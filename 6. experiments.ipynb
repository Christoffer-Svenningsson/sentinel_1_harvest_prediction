{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc76fa7-2b5a-44f3-9200-7d33f754eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from collections import namedtuple\n",
    "import pickle\n",
    "from decimal import Decimal as D\n",
    "from decimal import getcontext, ROUND_HALF_UP\n",
    "import datetime\n",
    "from time import time\n",
    "import uuid\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from boruta import BorutaPy\n",
    "\n",
    "from util_paths import SHARED_FOLDER_PATH\n",
    "from util_paths import DATASETS_PATH\n",
    "from util_paths import FEATURES_SELECTED_PATH\n",
    "from util_paths import EXPERIMENTS_PATH\n",
    "\n",
    "from models import *\n",
    "from utils_fvs_sampling_save import *\n",
    "\n",
    "#ANSI escape sequences\n",
    "PURPLE = '\\033[95m'\n",
    "CYAN = '\\033[96m'\n",
    "DARKCYAN = '\\033[36m'\n",
    "BLUE = '\\033[94m'\n",
    "GREEN = '\\033[92m'\n",
    "YELLOW = '\\033[93m'\n",
    "RED = '\\033[91m'\n",
    "BOLD = '\\033[1m'\n",
    "UNDERLINE = '\\033[4m'\n",
    "END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b46991-effe-4d8c-b3ac-eca5bbc8aefa",
   "metadata": {},
   "source": [
    "### Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582fc288-7ae2-44e7-8c13-41f2112dc333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_metrics(y_test, y_hat, err_tol=0.5):\n",
    "    y_test = np.array(y_test)\n",
    "    y_hat = np.array(y_hat)\n",
    "\n",
    "    y_test_class = y_test.round().astype(int)\n",
    "    y_hat_class = np.zeros(len(y_hat)) - 1\n",
    "\n",
    "    for i in range(len(y_test)):\n",
    "        y_t = 6.51\n",
    "        y_h = 7.1\n",
    "        \n",
    "        if np.abs(y_test[i] - y_hat[i]) <= err_tol:\n",
    "            y_hat_class[i] = y_test_class[i]\n",
    "            \n",
    "        else:\n",
    "            y_hat_class[i] = int(np.round(y_hat[i]))\n",
    "            \n",
    "            if y_hat_class[i] == y_test_class[i]:\n",
    "                if y_test[i] < y_hat[i]:\n",
    "                    y_hat_class[i] = y_hat_class[i] + 1\n",
    "                else:\n",
    "                    y_hat_class[i] = y_hat_class[i] - 1\n",
    "                    \n",
    "        \n",
    "    acc = metrics.accuracy_score(y_test_class, y_hat_class)\n",
    "    f1 =  metrics.f1_score(y_test_class, y_hat_class, average='weighted')\n",
    "    \n",
    "    return acc, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1cbe731-772c-4096-971e-d61e0eeb58aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_X_y(year, dataset, fv_type, selected_features):\n",
    "    cols = []\n",
    "    if fv_type == FeatureVector.All:\n",
    "        cols = [col for col in dataset.columns if is_in_all(col)]\n",
    "    \n",
    "    elif fv_type == FeatureVector.FeatureImportance:\n",
    "        cols = selected_features[year][\"all\"]\n",
    "        #cols = selected_features[year][\"confirmed\"]\n",
    "        cols = [col for col in cols if is_in_all(col)]\n",
    "    \n",
    "    elif fv_type == FeatureVector.VH_VV:\n",
    "        cols = [col for col in dataset.columns if is_vh_vv(col)]\n",
    "    \n",
    "    elif fv_type == FeatureVector.Weather:\n",
    "        cols = [col for col in dataset.columns if is_weather(col)]\n",
    "    \n",
    "    elif fv_type == FeatureVector.Topology:\n",
    "        cols = [col for col in dataset.columns if is_topology(col)]\n",
    "    \n",
    "    elif fv_type == FeatureVector.Height:\n",
    "        cols = [col for col in dataset.columns if is_height(col)]\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Unknown Feature vector type!\")\n",
    "        \n",
    "    X = dataset.loc[:, cols]\n",
    "    \n",
    "    y_reg = dataset.harvest\n",
    "    return X, y_reg\n",
    "\n",
    "\n",
    "import warnings\n",
    "# False positive of SettingWithCopyWarning, the dataframe in question gets updated.\n",
    "warnings.filterwarnings(\"ignore\", module=\"pandas\")\n",
    "\n",
    "def evaluate(\n",
    "    year, \n",
    "    data,\n",
    "    model_type,\n",
    "    fv_type,\n",
    "    sampling,\n",
    "    n_folds=5,\n",
    "    save_path=\"\",\n",
    "    selected_features=None,\n",
    "    err_tol=0.5\n",
    "):\n",
    "    data = data[data[\"year\"] == year].drop([\"year\"], axis=1)\n",
    "    \n",
    "    X, y_reg = get_X_y(year, data, fv_type, selected_features)\n",
    "    \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "    \n",
    "    rmses = np.full(n_folds, np.inf)\n",
    "    accs = np.zeros(n_folds)\n",
    "    f1s = np.zeros(n_folds)\n",
    "    \n",
    "    print(f\"Runnning kfold ...\")\n",
    "    start = time()\n",
    "    have_saved = False\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "        X_train, y_train = X.iloc[train_idx], y_reg.iloc[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y_reg.iloc[test_idx]\n",
    "        \n",
    "        assert not np.any(np.isnan(X_train)), \"NaNs in X_train BEFORE normalization\"\n",
    "        assert not np.any(np.isnan(X_test)), \"NaNs in X_test BEFORE normalization\"\n",
    "        \n",
    "        normalize(X_train, X_test)\n",
    "\n",
    "        assert not np.any(np.isnan(X_train)), \"NaNs in X_train AFTER normalization\"\n",
    "        assert not np.any(np.isnan(X_test)), \"NaNs in X_test AFTER normalization\"\n",
    "\n",
    "        model = get_model(X_train, y_train, model_type)\n",
    "        y_hat = model.predict(X_test)\n",
    "        rmses[fold] = metrics.mean_squared_error(y_test, y_hat, squared=False)\n",
    "        \n",
    "        if (\n",
    "            save_path != \"\" \n",
    "            and model_type == ModelType.LGBM_Regression \n",
    "            and fv_type == FeatureVector.All \n",
    "            and not have_saved\n",
    "        ):\n",
    "            save(\n",
    "                y_hat,\n",
    "                save_path,\n",
    "                f\"y_hat_{year}_{sampling.name}\",\n",
    "                \"npy\"\n",
    "            )\n",
    "            have_saved = True\n",
    "        \n",
    "        # Convert to classification problem\n",
    "        acc, f1 = class_metrics(y_test, y_hat, err_tol)\n",
    "        accs[fold] = acc\n",
    "        f1s[fold] = f1\n",
    "        \n",
    "    end = time()\n",
    "    print(f\"Elapsed time: {end-start}\")\n",
    "    return Result(rmses, accs, f1s, model_type, fv_type, year)\n",
    "        \n",
    "def finalize_result(res: Result):\n",
    "    print(f\"Resutls\")\n",
    "    print(\"Means\")\n",
    "    print(f\"{np.mean(res.rmses)}, RMSE\")\n",
    "    print(f\"{np.mean(res.accs)}, ACCURACY\")\n",
    "    print(f\"{np.mean(res.f1s)}, F1-SCORE\")\n",
    "    return AvgScore(np.mean(res.rmses), np.mean(res.accs), np.mean(res.f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3c6d7d1-a6af-4313-9330-8e7a16f28bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(data, models, fvs, sampling, run_name=\"\", save_path=\"\", selected_features=None, err_tol=0.5):\n",
    "    all_res = dict()\n",
    "    spacer = \" \"*6\n",
    "    \n",
    "    for year in YEARS:\n",
    "        print(f\"{RED}{BOLD}{UNDERLINE}{year}{END}: {sampling}\")\n",
    "        \n",
    "        res_year = dict()\n",
    "        for model in models:\n",
    "            print(f\"{spacer}{DARKCYAN}{BOLD}{model}{END}\")\n",
    "            res_year[model] = dict()\n",
    "            \n",
    "            for fv in fvs:\n",
    "                print(f\"{spacer*2}{BOLD}{fv}{END}\")\n",
    "                result = evaluate(\n",
    "                    year, \n",
    "                    data, \n",
    "                    model, \n",
    "                    fv, \n",
    "                    sampling, \n",
    "                    save_path=save_path, \n",
    "                    selected_features=selected_features,\n",
    "                    err_tol=err_tol\n",
    "                )\n",
    "                res_year[model][fv] = finalize_result(result)\n",
    "                print(\"-\"*20)\n",
    "                \n",
    "        if save_path != \"\":\n",
    "            save(\n",
    "                res_year,\n",
    "                save_path,\n",
    "                f\"res_{year}_{run_name}\",\n",
    "                \"pkl\",\n",
    "            )\n",
    "            \n",
    "        all_res[year] = res_year\n",
    "    return all_res\n",
    "\n",
    "def get_selected_features(sampling: Sampling):\n",
    "    path = \"\"\n",
    "    if sampling == Sampling.Grid_3x3_50m:\n",
    "        path = os.path.join(FEATURES_SELECTED_PATH, \"feature_selection.pkl\")\n",
    "    elif sampling == Sampling.Nearest_50m:\n",
    "        path = os.path.join(FEATURES_SELECTED_PATH, \"nearest\", \"feature_selection_nearest.pkl\")\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    with open(path, \"rb\") as file:\n",
    "        selected_features = pickle.load(file)\n",
    "        return selected_features\n",
    "    \n",
    "def create_root_folder(sampling):\n",
    "    root_folder = os.path.join(\n",
    "        EXPERIMENTS_PATH,\n",
    "        f\"{str(datetime.datetime.now().strftime('%h_%d_%H%M'))}_{sampling.name}\"\n",
    "    )\n",
    "    while os.path.exists(root_folder):\n",
    "        root_folder = os.path.join(\n",
    "            EXPERIMENTS_PATH,\n",
    "            str(datetime.datetime.now().strftime('%h_%d_%H:%M'))\n",
    "        )   \n",
    "        \n",
    "    os.makedirs(root_folder)\n",
    "    \n",
    "    return root_folder\n",
    "    \n",
    "\n",
    "def run_all(\n",
    "    models=None, \n",
    "    fvs=None, \n",
    "    samplings=None, \n",
    "    is_saving=True, \n",
    "    err_tol=0.5, \n",
    "    additional_name=None\n",
    "):\n",
    "    if not models:\n",
    "        models = [ModelType.LGBM_Regression, ModelType.FNN_Regression]\n",
    "    if not samplings:\n",
    "        samplings = list(Sampling)\n",
    "    \n",
    "    for sampling in samplings:\n",
    "        data = pd.read_feather(sampling_2_datasetpath_and_name[sampling][\"path\"])\n",
    "        if sampling == Sampling.Nearest_50m:\n",
    "            cols = [col for col in data.columns if is_nearest_sampling(col) or col == \"year\"]\n",
    "            data = data.loc[:, cols]\n",
    "            \n",
    "        dataset_name = sampling_2_datasetpath_and_name[sampling][\"name\"]\n",
    "\n",
    "        selected_features = get_selected_features(sampling)\n",
    "        save_path = create_root_folder(sampling) if is_saving else \"\"\n",
    "        print(save_path)\n",
    "        \n",
    "        all_res = run(\n",
    "            data, \n",
    "            models, \n",
    "            fvs if fvs is not None else get_fvs(sampling), \n",
    "            sampling,\n",
    "            run_name=f\"{sampling.name}_{dataset_name}\",\n",
    "            save_path=save_path, \n",
    "            selected_features=selected_features,\n",
    "            err_tol=err_tol\n",
    "        )\n",
    "        \n",
    "        if is_saving:\n",
    "            name = f\"results_{datetime.datetime.now().strftime('%h_%d_%H:%M')}_{sampling.name}_{dataset_name}\"\n",
    "            if err_tol > 0.5:\n",
    "                name += f\"_error_allowance_{err_tol}\"\n",
    "            \n",
    "            if additional_name is not None:\n",
    "                name += \"_\" + additional_name\n",
    "            \n",
    "            save(\n",
    "                all_res,\n",
    "                save_path,\n",
    "                name,\n",
    "                \"pkl\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f16952b2-3cda-478e-aa29-5e23e33843ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-23-428/Oliver/experiments/Dec_05_1830_Grid_3x3_50m\n",
      "\u001b[91m\u001b[1m\u001b[4m2017\u001b[0m: Sampling.Grid_3x3_50m\n",
      "      \u001b[36m\u001b[1mModelType.LGBM_Regression\u001b[0m\n",
      "            \u001b[1mFeatureVector.All\u001b[0m\n",
      "Runnning kfold ...\n",
      "Elapsed time: 4.738386154174805\n",
      "Resutls\n",
      "Means\n",
      "0.8066106112524137, RMSE\n",
      "0.9688929524924111, ACCURACY\n",
      "0.9670425696860983, F1-SCORE\n",
      "--------------------\n",
      "\u001b[91m\u001b[1m\u001b[4m2018\u001b[0m: Sampling.Grid_3x3_50m\n",
      "      \u001b[36m\u001b[1mModelType.LGBM_Regression\u001b[0m\n",
      "            \u001b[1mFeatureVector.All\u001b[0m\n",
      "Runnning kfold ...\n",
      "Elapsed time: 4.55283784866333\n",
      "Resutls\n",
      "Means\n",
      "0.7536440796019913, RMSE\n",
      "0.9795419847328244, ACCURACY\n",
      "0.9786463390021061, F1-SCORE\n",
      "--------------------\n",
      "\u001b[91m\u001b[1m\u001b[4m2019\u001b[0m: Sampling.Grid_3x3_50m\n",
      "      \u001b[36m\u001b[1mModelType.LGBM_Regression\u001b[0m\n",
      "            \u001b[1mFeatureVector.All\u001b[0m\n",
      "Runnning kfold ...\n",
      "Elapsed time: 6.4360129833221436\n",
      "Resutls\n",
      "Means\n",
      "0.922127830556305, RMSE\n",
      "0.9636467236467237, ACCURACY\n",
      "0.9619791693727014, F1-SCORE\n",
      "--------------------\n",
      "\u001b[91m\u001b[1m\u001b[4m2020\u001b[0m: Sampling.Grid_3x3_50m\n",
      "      \u001b[36m\u001b[1mModelType.LGBM_Regression\u001b[0m\n",
      "            \u001b[1mFeatureVector.All\u001b[0m\n",
      "Runnning kfold ...\n",
      "Elapsed time: 6.089205741882324\n",
      "Resutls\n",
      "Means\n",
      "1.0784940055235799, RMSE\n",
      "0.9297871099605348, ACCURACY\n",
      "0.9294355099317789, F1-SCORE\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "YEARS = [2017,2018,2019,2020]\n",
    "\n",
    "run_all(\n",
    "    samplings=[Sampling.Grid_3x3_50m],\n",
    "    models=[ModelType.LGBM_Regression],\n",
    "    fvs=[FeatureVector.All],\n",
    "    err_tol=2.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62005d7e-363b-4bbd-a1af-f596ea2642d0",
   "metadata": {},
   "source": [
    "## Create tables for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6711d4e9-cbf8-48c1-aa0d-edb7d7539bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_paths():\n",
    "    paths = glob.glob(os.path.join(EXPERIMENTS_PATH, \"Important\", \"*\", \"results_*\"))\n",
    "    list(enumerate(paths))\n",
    "    return paths\n",
    "\n",
    "paths = res_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42c5cd63-dd83-4ec1-8f56-cb09580c3c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "results_Dec_05_16:06_Grid_3x3_50m_alot2.pkl\n",
      "\n",
      "1\n",
      "results_Dec_05_16:43_Nearest_22m_hd_22m.pkl\n",
      "\n",
      "2\n",
      "results_Dec_05_16:13_Nearest_50m_alot2.pkl\n",
      "\n",
      "3\n",
      "results_Dec_05_16:15_Rfi_Grid_50m_rfi_filtered.pkl\n",
      "\n",
      "4\n",
      "results_Dec_05_17:46_Nearest_12m_hd_12m.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(paths):\n",
    "    print(i)\n",
    "    print(p.split(\"/\")[-1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f5e2ee3-36b8-4158-8140-f8d1579e9068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mimer/NOBACKUP/groups/snic2022-23-428/Oliver/experiments/Dec_05_1643_nearest_12/results_Dec_05_17:46_Nearest_12m_hd_12m.pkl\n"
     ]
    }
   ],
   "source": [
    "res_path = paths[2]\n",
    "print(res_path)\n",
    "\n",
    "with open(res_path, \"rb\") as file:\n",
    "    all_res = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "085a578c-3baf-4aae-a96f-33330f49cdda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Sampling.Nearest_12m: 5>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sampling_from(path):\n",
    "    if \"Rfi_Grid\" in path:\n",
    "        return Sampling.Rfi_Grid_50m\n",
    "    elif \"Grid_3x3_50m\" in path:\n",
    "        return Sampling.Grid_3x3_50m\n",
    "    \n",
    "    elif \"Nearest_50m\" in path:\n",
    "        return Sampling.Nearest_50m\n",
    "    elif \"Nearest_22m\" in path:\n",
    "        return Sampling.Nearest_22m\n",
    "    elif \"Nearest_12m\" in path:\n",
    "        return Sampling.Nearest_12m\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown sampling for res path: {path}\")\n",
    "\n",
    "sampling = get_sampling_from(res_path)\n",
    "sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "225b2138-087f-4867-b964-8be6a7c6acad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling.Nearest_12m\n",
      "All & 1.31 & 0.43 & 0.41 & 1.49 & 0.37 & 0.36 \\\\ \n",
      "VH \\& VV & 1.34 & 0.42 & 0.40 & 1.53 & 0.36 & 0.34 \\\\ \n",
      "Weather & 1.56 & 0.35 & 0.32 & 1.60 & 0.33 & 0.29 \\\\ \n",
      "Topology & 1.84 & 0.25 & 0.16 & 1.86 & 0.26 & 0.17 \\\\ \n",
      "Elevation & 1.72 & 0.30 & 0.25 & 1.80 & 0.27 & 0.19 \\\\ \n",
      "\n",
      "All & 1.00 & 0.50 & 0.49 & 1.14 & 0.42 & 0.41 \\\\ \n",
      "VH \\& VV & 1.02 & 0.49 & 0.48 & 1.11 & 0.45 & 0.44 \\\\ \n",
      "Weather & 1.43 & 0.32 & 0.27 & 1.47 & 0.31 & 0.24 \\\\ \n",
      "Topology & 1.74 & 0.26 & 0.17 & 1.76 & 0.26 & 0.18 \\\\ \n",
      "Elevation & 1.57 & 0.30 & 0.24 & 1.64 & 0.28 & 0.22 \\\\ \n",
      "\n",
      "All & 1.37 & 0.39 & 0.38 & 1.50 & 0.35 & 0.34 \\\\ \n",
      "VH \\& VV & 1.42 & 0.38 & 0.36 & 1.52 & 0.33 & 0.32 \\\\ \n",
      "Weather & 1.75 & 0.26 & 0.23 & 1.86 & 0.24 & 0.21 \\\\ \n",
      "Topology & 2.15 & 0.17 & 0.08 & 2.17 & 0.16 & 0.08 \\\\ \n",
      "Elevation & 2.05 & 0.19 & 0.14 & 2.09 & 0.17 & 0.11 \\\\ \n",
      "\n",
      "All & 1.53 & 0.36 & 0.36 & 1.81 & 0.31 & 0.30 \\\\ \n",
      "VH \\& VV & 1.63 & 0.34 & 0.33 & 1.92 & 0.31 & 0.30 \\\\ \n",
      "Weather & 2.10 & 0.22 & 0.20 & 2.45 & 0.21 & 0.18 \\\\ \n",
      "Topology & 3.06 & 0.17 & 0.10 & 3.08 & 0.18 & 0.10 \\\\ \n",
      "Elevation & 2.87 & 0.17 & 0.13 & 3.01 & 0.16 & 0.12 \\\\ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def latex_entry(results, year, sampling):\n",
    "    col_names = {\n",
    "        FeatureVector.All: \"All\",\n",
    "        FeatureVector.FeatureImportance: \"Feature importance\",\n",
    "        FeatureVector.VH_VV: r\"VH \\& VV\",\n",
    "        FeatureVector.Weather: \"Weather\",\n",
    "        FeatureVector.Topology: \"Topology\",\n",
    "        FeatureVector.Height: \"Elevation\",\n",
    "    }\n",
    "    \n",
    "    for fv in get_fvs(sampling):        \n",
    "        t_data = f\"{col_names[fv]}\"\n",
    "        #t_data = \"\"\n",
    "        for model in list(ModelType):\n",
    "            if not model in results[year]:\n",
    "                continue\n",
    "                \n",
    "            res = results[year][model][fv]\n",
    "            t_data += f\" & {my_round(res.rmse_mean)} & {my_round(res.accs_mean)} & {my_round(res.f1s_mean)}\"\n",
    "            \n",
    "        t_data += r\" \\\\ \"\n",
    "        print(t_data)\n",
    "        \n",
    "print(sampling)\n",
    "\n",
    "year = 2017\n",
    "for year in YEARS:\n",
    "    latex_entry(all_res, year, sampling)\n",
    "    print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb1429-de3e-454d-b0b3-6d6522d19f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd1ee090-57ce-434b-90cd-1b37cd74bc6b",
   "metadata": {},
   "source": [
    "### Varying error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5d79c6b6-f80b-49cf-82b0-bcbb0f92b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_entry_error_allowance():\n",
    "    \n",
    "    # Fetch resutls with > 0.5\n",
    "    paths = glob.glob(os.path.join(EXPERIMENTS_PATH, \"Important\", \"*_err_*\", \"results_*\"))\n",
    "    all_res = dict()\n",
    "    \n",
    "    pattern = r\"error_allowance_(\\d+.\\d*)\"\n",
    "    \n",
    "    for path in sorted(paths):\n",
    "        res = re.search(pattern, path)\n",
    "        \n",
    "        name = path.split(\".\")[0][-5:]\n",
    "        with open(path, \"rb\") as file:\n",
    "            all_res[res.groups()[0]] = pickle.load(file)\n",
    "    \n",
    "    # Fetch resutls with 0.5, baseline\n",
    "    path_05 = glob.glob(os.path.join(EXPERIMENTS_PATH, \"Important\", \"*_grid_50\", \"results_*\"))[0]\n",
    "    with open(path_05, \"rb\") as file:\n",
    "        all_res[\"0.5\"] = pickle.load(file)\n",
    "    \n",
    "    for err_tol in sorted(all_res):\n",
    "        t_data = err_tol\n",
    "            \n",
    "        for year in YEARS:\n",
    "            res = all_res[err_tol][year][ModelType.LGBM_Regression][FeatureVector.All]\n",
    "            t_data += f\" & {my_round(res.accs_mean)} & {my_round(res.f1s_mean)}\"\n",
    "        t_data += r\" \\\\ \"\n",
    "        print(t_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fb939716-4b2d-4ae6-a5a1-b12a68311c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 & 0.56 & 0.55 & 0.60 & 0.59 & 0.50 & 0.50 & 0.44 & 0.44 \\\\ \n",
      "0.75 & 0.72 & 0.71 & 0.76 & 0.76 & 0.67 & 0.67 & 0.60 & 0.60 \\\\ \n",
      "1. & 0.83 & 0.82 & 0.86 & 0.86 & 0.79 & 0.78 & 0.72 & 0.72 \\\\ \n",
      "1.25 & 0.90 & 0.89 & 0.91 & 0.91 & 0.86 & 0.86 & 0.80 & 0.79 \\\\ \n",
      "1.5 & 0.94 & 0.93 & 0.95 & 0.94 & 0.91 & 0.91 & 0.86 & 0.86 \\\\ \n",
      "1.75 & 0.96 & 0.95 & 0.97 & 0.96 & 0.94 & 0.94 & 0.90 & 0.90 \\\\ \n",
      "2.0 & 0.97 & 0.97 & 0.98 & 0.98 & 0.96 & 0.96 & 0.93 & 0.93 \\\\ \n"
     ]
    }
   ],
   "source": [
    "latex_entry_error_allowance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2dc06a56-2d30-4ae1-a5dd-585e271aeb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AvgScore(rmse_mean=1.0824188819998612, accs_mean=0.6045091172849799, f1s_mean=0.6023207487537051)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res[\"0.75\"][year][ModelType.LGBM_Regression][FeatureVector.All]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d668776-efca-4c3a-9804-1d12a0549827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94031f-2da0-48bb-8246-b456464d2005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1266ad3e-53b7-47aa-b6c3-fc84fdb47d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_entry_error_allowance_old(all_res, years, errors):\n",
    "    for err in errors:\n",
    "        t_data = f\"{err}\"\n",
    "        for year in years:\n",
    "            res = all_res[year][ModelType.LGBM_Regression][FeatureVector.All][err]\n",
    "            t_data += f\" & {my_round(res.accs_mean)} & {my_round(res.f1s_mean)}\"\n",
    "            \n",
    "        t_data += r\" \\\\ \"\n",
    "        print(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa5f65-e737-4a6a-9f6f-a851fc04e9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f75d8d-bfcf-4429-ae42-4c15b2cca3ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transfer learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc603773-0909-426e-b0a5-17a59e983cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for year in YEARS:\n",
    "    print(f\"{RED}{BOLD}{UNDERLINE}{year}{END}: {sampling}\")\n",
    "\n",
    "    all_res[year] = dict()\n",
    "    for model in models:\n",
    "        print(f\"{spacer}{DARKCYAN}{BOLD}{model}{END}\")\n",
    "        all_res[year][model] = dict()\n",
    "\n",
    "        for fv in fvs:\n",
    "            print(f\"{spacer*2}{BOLD}{fv}{END}\")\n",
    "            all_res[year][model][fv] = dict()\n",
    "\n",
    "            for err in errors:\n",
    "                print(f\"{spacer*3}{BOLD}{PURPLE}Error allowed: +-{err}{END}\")\n",
    "                result = evaluate2(year, data, model, fv, sampling, err_allowance=err)\n",
    "                all_res[year][model][fv][err] = finalize_result(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a0ab141e-61d7-4ae9-adac-a401492cdc5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1m\u001b[4mTraining year 2017\u001b[0m\n",
      "   \u001b[36m\u001b[1mTest year 2018\u001b[0m\n",
      "TransferRes(rmse=4.443351692480902, acc=0.016216216216216217, f1=0.01104951104951105)\n",
      "   \u001b[36m\u001b[1mTest year 2019\u001b[0m\n",
      "TransferRes(rmse=1.7305867660831005, acc=0.1918918918918919, f1=0.1677038036900035)\n",
      "   \u001b[36m\u001b[1mTest year 2020\u001b[0m\n",
      "TransferRes(rmse=2.300130924300765, acc=0.16486486486486487, f1=0.13567802275667445)\n",
      "----------\n",
      "\u001b[91m\u001b[1m\u001b[4mTraining year 2018\u001b[0m\n",
      "   \u001b[36m\u001b[1mTest year 2017\u001b[0m\n",
      "TransferRes(rmse=3.9083783425043137, acc=0.03048780487804878, f1=0.018768873403019748)\n",
      "   \u001b[36m\u001b[1mTest year 2019\u001b[0m\n",
      "TransferRes(rmse=3.0712976897372446, acc=0.06707317073170732, f1=0.05521045810455782)\n",
      "   \u001b[36m\u001b[1mTest year 2020\u001b[0m\n",
      "TransferRes(rmse=3.1402514535478034, acc=0.08536585365853659, f1=0.04884064781927147)\n",
      "----------\n",
      "\u001b[91m\u001b[1m\u001b[4mTraining year 2019\u001b[0m\n",
      "   \u001b[36m\u001b[1mTest year 2017\u001b[0m\n",
      "TransferRes(rmse=1.9873761741026732, acc=0.1560364464692483, f1=0.15642369468042697)\n",
      "   \u001b[36m\u001b[1mTest year 2018\u001b[0m\n",
      "TransferRes(rmse=3.5257262402302048, acc=0.02733485193621868, f1=0.00852524892269837)\n",
      "   \u001b[36m\u001b[1mTest year 2020\u001b[0m\n",
      "TransferRes(rmse=2.037087750417541, acc=0.1845102505694761, f1=0.16627366824630635)\n",
      "----------\n",
      "\u001b[91m\u001b[1m\u001b[4mTraining year 2020\u001b[0m\n",
      "   \u001b[36m\u001b[1mTest year 2017\u001b[0m\n",
      "TransferRes(rmse=1.6896531120149239, acc=0.2213225371120108, f1=0.22745744490371006)\n",
      "   \u001b[36m\u001b[1mTest year 2018\u001b[0m\n",
      "TransferRes(rmse=3.75289772766986, acc=0.021592442645074223, f1=0.011350657509439473)\n",
      "   \u001b[36m\u001b[1mTest year 2019\u001b[0m\n",
      "TransferRes(rmse=2.1597334414815106, acc=0.1794871794871795, f1=0.19268126762691934)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "TransferRes = namedtuple(\"TransferRes\", [\"rmse\", \"acc\", \"f1\"])\n",
    "\n",
    "import warnings\n",
    "# False positive of SettingWithCopyWarning\n",
    "warnings.filterwarnings(\"ignore\", module=\"pandas\")\n",
    "\n",
    "import random\n",
    "\n",
    "def transfer():\n",
    "    YEARS = [2017, 2018, 2019, 2020]\n",
    "    n_years = len(YEARS)\n",
    "    \n",
    "    file = f\"dataset_y_2017_2020_alot2.feather\"\n",
    "    path = os.path.join(DATASETS_PATH, file)\n",
    "    data = pd.read_feather(path)\n",
    "    \n",
    "    dataset_name = \"alot2\"\n",
    "    fv = FeatureVector.All\n",
    "    sampling = Sampling.Grid_3x3_50m\n",
    "    \n",
    "    results = dict()\n",
    "    spacer = \" \"*3\n",
    "    \n",
    "    for year_x in YEARS:\n",
    "        results[year_x] = dict()\n",
    "        print(f\"{RED}{BOLD}{UNDERLINE}Training year {year_x}{END}\")\n",
    "        for year_y in YEARS:\n",
    "            if year_x == year_y:\n",
    "                continue\n",
    "            \n",
    "            print(f\"{spacer}{DARKCYAN}{BOLD}Test year {year_y}{END}\")\n",
    "            dataset_x = data[data[\"year\"] == year_x].drop([\"year\"], axis=1)\n",
    "            dataset_y = data[data[\"year\"] == year_y].drop([\"year\"], axis=1)\n",
    "\n",
    "            X, y_reg = get_X_y(year_x, dataset_x, fv, None)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y_reg, test_size=0.1)\n",
    "\n",
    "            if year_x != year_y:\n",
    "                size_test = len(y_test)\n",
    "                X, y_reg = get_X_y(year_y, dataset_y, fv, None)\n",
    "                \n",
    "                idxs = list(range(len(X)))\n",
    "                random.shuffle(idxs)\n",
    "                \n",
    "                X_test = X.iloc[idxs[:size_test]]\n",
    "                y_test = y_reg.iloc[idxs[:size_test]]\n",
    "\n",
    "            model = get_lgbm_regressor(X_train, y_train)\n",
    "            y_hat = model.predict(X_test)\n",
    "            rmse = metrics.mean_squared_error(y_test, y_hat, squared=False)\n",
    "            \n",
    "             # Convert to classification problem\n",
    "            acc, f1 = class_metrics(y_test, y_hat)\n",
    "\n",
    "            \n",
    "            results[year_x][year_y] = TransferRes(rmse, acc, f1)\n",
    "            print(f\"{results[year_x][year_y]}\")\n",
    "            \n",
    "        print(\"-\"*10)\n",
    "    \n",
    "    name = f\"trans_results_{datetime.date.today().strftime('%m_%d')}_{dataset_name}_{fv.name}_{sampling.name}\"\n",
    "    save(\n",
    "        results,\n",
    "        EXPERIMENTS_PATH,\n",
    "        name,\n",
    "        \"pkl\",\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "trans_res = transfer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a00a06b9-573c-4e05-ad61-e5b9a4e70709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_entry_trans(trans_res, years):\n",
    "    i = 0\n",
    "    for year_x in YEARS:\n",
    "        for year_y in YEARS:\n",
    "            if year_x == year_y:\n",
    "                continue\n",
    "                \n",
    "            t_data = f\"{year_x} & {year_y} \"\n",
    "            res = trans_res[year_x][year_y]\n",
    "            t_data += f\" & {my_round(res.rmse)} & {my_round(res.acc)} & {my_round(res.f1)}\"\n",
    "\n",
    "            t_data += r\" \\\\ \"\n",
    "            \n",
    "            i+=1\n",
    "            if i % 3 == 0 and year_x != 2020:\n",
    "                t_data += r\"\\midrule \"\n",
    "            print(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "78f92df3-9f69-4dd1-b736-78628424df8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 & 2018  & 4.44 & 0.02 & 0.01 \\\\ \n",
      "2017 & 2019  & 1.73 & 0.19 & 0.17 \\\\ \n",
      "2017 & 2020  & 2.30 & 0.16 & 0.14 \\\\ \\midrule \n",
      "2018 & 2017  & 3.91 & 0.03 & 0.02 \\\\ \n",
      "2018 & 2019  & 3.07 & 0.07 & 0.06 \\\\ \n",
      "2018 & 2020  & 3.14 & 0.09 & 0.05 \\\\ \\midrule \n",
      "2019 & 2017  & 1.99 & 0.16 & 0.16 \\\\ \n",
      "2019 & 2018  & 3.53 & 0.03 & 0.01 \\\\ \n",
      "2019 & 2020  & 2.04 & 0.18 & 0.17 \\\\ \\midrule \n",
      "2020 & 2017  & 1.69 & 0.22 & 0.23 \\\\ \n",
      "2020 & 2018  & 3.75 & 0.02 & 0.01 \\\\ \n",
      "2020 & 2019  & 2.16 & 0.18 & 0.19 \\\\ \n"
     ]
    }
   ],
   "source": [
    "latex_entry_trans(trans_res, YEARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "eec39c29-274e-4b14-9d3c-b70f5c1b6933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3%44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5cbb0a-27e3-4b9e-bdf7-b39f098222e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ad3dc-f87b-4c2e-893b-da8887e80570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b695cd-c78b-4199-9ae9-e75fe499ca77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3462ad-383c-4e71-8eb5-e20f56768b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a37cc6-c2f4-4313-adf5-1d38f84328d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c24899e-2899-46b6-ab02-8382ebfc1283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca529b3-0e81-44d9-851c-80e6bf108fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a586f4-d9f8-47c4-9fa0-28a0f4b3cbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb0f72-83c4-40fc-af2e-c7daf678dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def old():\n",
    "    def reg2class(y_test, y_hat):\n",
    "        return y_test.round().astype(int), y_hat.round().astype(int)\n",
    "\n",
    "    def class_metrics(y_test, y_hat, err_tol):\n",
    "        y_test, y_hat = reg2class(y_test, y_hat)\n",
    "        if err_tol > 0.0:\n",
    "            y_hat = allow_error(y_test, y_hat, err_tol)\n",
    "\n",
    "        return metrics.accuracy_score(y_test, y_hat), metrics.f1_score(y_test, y_hat, average='weighted')\n",
    "\n",
    "    def allow_error(y_test, y_hat, err_tol=1):\n",
    "        # Does not support confusion matrix\n",
    "        y_test = np.array(y_test)\n",
    "        y_hat = np.array(y_hat)\n",
    "\n",
    "        for i in range(len(y_test)):\n",
    "            if np.abs(y_test[i] - y_hat[i]) <= err_tol:\n",
    "                y_hat[i] = y_test[i]\n",
    "        return y_hat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Python",
   "language": "python",
   "name": "my_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
