{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Sentinel-1 data\n",
    "- This notebook finds which eo-patches we need based on a chosen region defined with polygons from a geojson file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import pyproj\n",
    "import gzip\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "from eolearn.core import (\n",
    "    EOTask,\n",
    "    EOPatch,\n",
    "    EONode,\n",
    "    EOWorkflow,\n",
    "    OverwritePermission,\n",
    "    LoadTask,\n",
    "    SaveTask,\n",
    "    FeatureType,\n",
    "    linearly_connect_tasks,\n",
    "    CreateEOPatchTask\n",
    ")\n",
    "from sentinelhub import CRS, BBoxSplitter\n",
    "from eolearn.io import SentinelHubInputTask\n",
    "from sentinelhub import DataCollection, SHConfig, ResamplingType\n",
    "from sentinelhub.data_collections import _Resolution\n",
    "\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from util_paths import SWEDEN\n",
    "from util_paths import HARVEST_17_20_AOI_FILE\n",
    "from util_paths import SENTINEL_1_11x11_PATH\n",
    "from util_paths import UTM33N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Area Of Interest (AOI) to find which eo-patches we need to download\n",
    " - AOI file should be a geojson with multipolygon features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = gpd.read_file(HARVEST_17_20_AOI_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvest_aoi = aoi\n",
    "aoi_shape = harvest_aoi.geometry.values[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also load multipolygon of Sweden to view the selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweden_gdf = gpd.read_file(SWEDEN)\n",
    "sweden_gdf = sweden_gdf.to_crs(crs = UTM33N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoi_grid(aoi, target_crs=UTM33N, grid_size=2500, save=False):\n",
    "    \"\"\"\n",
    "    read in shape file and reproject it into the projection that will compute correct aoi size\n",
    "    \n",
    "    Args:\n",
    "        shp: the AOI shapfile either in ESRI shapefile or geojson\n",
    "        t_crs: the target coordination;\n",
    "        gr_sz: tile/grid size to split the AOI, default is 168 by 168 pixels;\n",
    "        save: save the generated AOI tile grid as a pickle file\n",
    "    Return:\n",
    "        patchID: the splitted tile that will be saved as EOpatch with the IDs\n",
    "\n",
    "    Note:\n",
    "        when save is set to Ture. An ESRI shapefile is saved to the disk under folder called \"aoi_tile_grid\"\n",
    "    \"\"\"\n",
    "    #reading shapefile using geopandas\n",
    "    aoi_geo = gpd.read_file(aoi)\n",
    "    #reproject the AOI to a target CRS that will give a correct AOI size in m2\n",
    "    aoi_reprj = aoi_geo.to_crs(crs=target_crs)\n",
    "    #get the AOI geometry\n",
    "    aoi_shape = aoi_reprj.geometry.values[-1]\n",
    "    # get the width and height (sentinel-2 in 10m resolution)\n",
    "    s2_res = 10\n",
    "    width_pix = int((aoi_shape.bounds[2] - aoi_shape.bounds[0])/s2_res)\n",
    "    heigth_pix = int((aoi_shape.bounds[3] - aoi_shape.bounds[1])/s2_res)\n",
    "    print('Dimension of the area is {} x {} pixels'.format(width_pix, heigth_pix))\n",
    "    width_grid = int(round(width_pix/grid_size))\n",
    "    heigth_grid = int(round(heigth_pix/grid_size))\n",
    "\n",
    "    # split the tile grid by the desired grid number\n",
    "    tile_splitter = BBoxSplitter([aoi_shape], target_crs, (width_grid, heigth_grid))\n",
    "    print(\"The area is splitted into a grid with {} by {} tiles!\".format(width_grid, heigth_grid))\n",
    "\n",
    "    tiles = np.array(tile_splitter.get_bbox_list())\n",
    "    info_list = np.array(tile_splitter.get_info_list())\n",
    "\n",
    "    # get the all polygon inform  i AOI\n",
    "    idxs_x = [info['index_x'] for info in tile_splitter.info_list]\n",
    "    idxs_y = [info['index_y'] for info in tile_splitter.info_list]\n",
    "\n",
    "    #save all the patch ID for tiles and save it as numpy array\n",
    "    patchID = np.array(range(len(tiles))).astype(\"int\")\n",
    "    geometry = [Polygon(bbox_.get_polygon()) for bbox_ in tiles[patchID]]\n",
    "\n",
    "    return patchID, tiles, tile_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_ids, tile_list, bbox_splitter = aoi_grid(SWEDEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_list = np.array(bbox_splitter.get_bbox_list())\n",
    "info_list = np.array(bbox_splitter.get_info_list())\n",
    "\n",
    "# Prepare info of selected EOPatches\n",
    "geometry = [Polygon(bbox.get_polygon()) for bbox in bbox_list]\n",
    "idxs = [list(info_list).index(info) for info in info_list]\n",
    "#idxs = [info.index for info in info_list]\n",
    "idxs_x = [info['index_x'] for info in info_list]\n",
    "idxs_y = [info['index_y'] for info in info_list]\n",
    "\n",
    "bbox_gdf = gpd.GeoDataFrame({'index': idxs, 'index_x': idxs_x, 'index_y': idxs_y}, \n",
    "                            crs=UTM33N, geometry=geometry)\n",
    "\n",
    "df = pd.DataFrame({'index_x':idxs_x, 'index_y':idxs_y})\n",
    "patches_gdf = gpd.GeoDataFrame(df, crs=UTM33N, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_ids = [index for (index, patch) in patches_gdf.iterrows() if harvest_aoi.geometry[0].intersects(patch.geometry)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontdict = {'family': 'monospace', 'weight': 'normal', 'size': 30}\n",
    "fontdict1 = {'family': 'monospace', 'weight': 'normal', 'size': 20}\n",
    "# if bboxes have all same size, estimate offset\n",
    "xl, yl, xu, yu = patches_gdf.geometry[0].bounds\n",
    "xoff, yoff = (xu-xl)/4, (yu-yl)/4          #<--------- Why 3 and 5?\n",
    "# figure\n",
    "fig, ax = plt.subplots(figsize=(25,25))\n",
    "patches_gdf.plot(ax=ax,facecolor='w',edgecolor='r',alpha=0.5)\n",
    "sweden_gdf.plot(ax=ax, facecolor='w',edgecolor='b',alpha=0.5)\n",
    "ax.set_title('Sweden tiled in a 15 x 35 grid');\n",
    "\n",
    "# add annotiation text\n",
    "for idx in patches_gdf.index:\n",
    "    eop_name = '{0}x{1}'.format(patches_gdf.index_x[idx], patches_gdf.index_y[idx])\n",
    "    centroid, = list(patches_gdf.geometry[idx].centroid.coords)\n",
    "    ax.text(centroid[0]-xoff, centroid[1]+yoff/2, '{}'.format(idx), fontdict=fontdict)\n",
    "    ax.text(centroid[0]-xoff, centroid[1]-yoff, eop_name, fontdict=fontdict1)\n",
    "\n",
    "# Mark bboxes of selected area\n",
    "# Run below first!!!\n",
    "bbox_gdf[bbox_gdf.index.isin(patch_ids)].plot(ax=ax, facecolor='g', edgecolor='r', alpha=0.5)\n",
    "ax.set_xlim([300000, 600000])\n",
    "ax.set_ylim([6100000, 6300000])\n",
    "plt.xticks(fontsize=34)\n",
    "plt.yticks(fontsize=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SentinelHub-credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTANCE_ID = ''\n",
    "CLIENT_ID = ''\n",
    "CLIENT_SECRET = ''\n",
    "\n",
    "config = SHConfig()\n",
    "\n",
    "if CLIENT_ID and CLIENT_SECRET and INSTANCE_ID:\n",
    "    config.instance_id = INSTANCE_ID\n",
    "    config.sh_client_id = CLIENT_ID\n",
    "    config.sh_client_secret = CLIENT_SECRET\n",
    "\n",
    "if config.sh_client_id == '' or config.sh_client_secret == '' or config.instance_id == '':\n",
    "    print(\"Warning! To use Sentinel Hub services, please provide the credentials (client ID and client secret).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main download function\n",
    " - By default we download the IW product with orthorectification\n",
    " - Max supported resolution is 11x11$m^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(time_interval, save_path, resolution, processing_params=None):\n",
    "    create_task = CreateEOPatchTask()\n",
    "    create_node = EONode(create_task, inputs=[], name=\"create eo-patch\")\n",
    "    \n",
    "    if not processing_params:\n",
    "        # Default params, contains orthorectifaction and radiometric calibration parameters\n",
    "        processing_params = {\n",
    "            \"backCoeff\": \"GAMMA0_TERRAIN\",\n",
    "            \"orthorectify\": True,\n",
    "            \"demInstance\": \"COPERNICUS\",\n",
    "            \"downsampling\": \"BILINEAR\",\n",
    "            \"upsampling\": \"BILINEAR\"\n",
    "        }\n",
    "\n",
    "    bands = [\"VH\", \"VV\"] # seems to return in alphabetical order\n",
    "    # bands = [\"VV\", \"VH\", \"HH\", \"HV\"] NOTE! Not supported\n",
    "    data_task = SentinelHubInputTask(\n",
    "        data_collection=DataCollection.SENTINEL1_IW,\n",
    "        bands_feature=(FeatureType.DATA, \"IW\"),\n",
    "        bands=bands,\n",
    "        config=config,\n",
    "        time_difference=datetime.timedelta(minutes=120),\n",
    "        max_threads=4,\n",
    "        resolution=resolution,\n",
    "        aux_request_args = {'processing': processing_params}\n",
    "    )\n",
    "    data_node = EONode(data_task, inputs=[create_node], name=\"data eo-patch\")\n",
    "\n",
    "    save_task = SaveTask(save_path, compress_level=1, overwrite_permission=OverwritePermission.OVERWRITE_PATCH)\n",
    "    save_node = EONode(save_task, inputs=[data_node], name=\"save eo-patch\")\n",
    "\n",
    "    workflow = EOWorkflow([create_node, data_node, save_node])\n",
    "\n",
    "\n",
    "    for idx in tqdm(patch_ids):\n",
    "        bbox = bbox_splitter.bbox_list[idx]\n",
    "        info = bbox_splitter.info_list[idx]\n",
    "        patch_name = f'eopatch_{idx}'\n",
    "        print(patch_name)\n",
    "        if os.path.exists(os.path.join(save_path, patch_name)):\n",
    "            print(\"patch is already downloaded, moving on ...\")\n",
    "            print()\n",
    "            continue\n",
    "        try:\n",
    "            print(\"executing workflow\")\n",
    "            workflow.execute({\n",
    "                create_node: {'bbox': bbox},\n",
    "                data_node: {'time_interval': time_interval},\n",
    "                save_node: {'eopatch_folder': patch_name}\n",
    "            })\n",
    "            print(\"executing workflow, done!\")\n",
    "                \n",
    "        except Exception as ex:\n",
    "            print(f'Failed {patch_name} with {ex}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customize download settings\n",
    " - Time period, save paths etc\n",
    " - Stores matrix with shape (time, y, x, polarization), polarization is in order VH, VV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download():\n",
    "    years = [\n",
    "        #2017,\n",
    "        #2018,\n",
    "        #2019,\n",
    "        2020,\n",
    "        #2021,\n",
    "        #2022\n",
    "    ]\n",
    "\n",
    "    # April to end of July\n",
    "    start_mm = \"04\"\n",
    "    start_dd = \"01\"\n",
    "    end_mm = \"07\"\n",
    "    end_dd = \"30\"\n",
    "\n",
    "    SENTINEL_1_PATH = SENTINEL_1_11x11_PATH\n",
    "    for year in years:\n",
    "        time_interval =  [f\"{year}-{start_mm}-{start_dd}\", f\"{year}-{end_mm}-{end_dd}\"]\n",
    "        save_path = os.path.join(SENTINEL_1_PATH, str(year))\n",
    "        resolution = 11.0\n",
    "        print(time_interval)\n",
    "        print(f\"resolution: {resolution} m\")\n",
    "        print(f\"starting download: {save_path}\")\n",
    "        download_data(time_interval, save_path, resolution)\n",
    "        \n",
    "#download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-exjobb]",
   "language": "python",
   "name": "conda-env-.conda-exjobb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "070d1b75123ca5a957ecbd215a31cd759d4129262fa051716ae8bfc212de46e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
